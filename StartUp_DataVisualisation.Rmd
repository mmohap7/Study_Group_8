---
title: "StartUp_DataVisualisation"
author: "Study Group 8"
date: "`r Sys.Date()`"
output: 
    html_document:
      number_sections: true
      highlight: haddock
      theme: spacelab
      toc: yes
      toc_depth: 2
      toc_float:
        collapsed: false
      fontzize: 10pt
---

# Introduction
What predicts start-up success? As six entrepreneurial-minded students from LBS, we wanted to understand better how start-up success can be predicted. Which industry receive higher fundings and which locations contribute to a higher probability of being acquired?
We would love to start our own venture in the US and find out more about trends in the start-up world there and how will can increases our chances of being successful.

In order to find out what we should do and how we should get there we will look into different aspects of our new venture called "Kostis" (too much? haha).
Firstly, we will investigate the category...
Secondly, we will look at location
Lastly, at time and when we should plan to reach our first milestones and secure funding rounds. 
In the end we will use the insights gained from this and build a prediction model for our venture "Kostis"

##### Notes
Notes
- category: what is the most successful category? JUN, MELONICA
- location: where: map: Draw a startups map, identifying the next Silicon Valley. RICK, MEHDI
    Idea Josi: Maybe we can also compare it to population ? Startups per population?
- time PEIJUN, JOSI
    when do we have to reach our milestones
    when do we have to our first/second/third funding round as well as funding amount
    
=> Build a model with it, to get highest success in start-up world in the US

Overall theme & color scheme: 

The goal of this report is to   
  - Trace the startups funding trend in recent years.
  - Draw a startups map, identifying the next Silicon Valley.
  - Utilise data modelling to select the features that might influence startups funding and outcomes.
  - Predict a startup's future based on its current characteristics.
  - Bring out customised advise to startups according to their segmentation.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(mice) 
library(VIM)
library(dplyr)
library(Hmisc)
library(janitor)
library(here)
library(skimr)
library(rsample)
library(readr)
library(sf)
remotes::install_github("UrbanInstitute/urbnmapr")
library(urbnmapr)
```
<style>
div.navy1 { background-color:#686868; border-radius: 5px; padding: 20px; border-style: groove; color: #ffffff;}

</style>

<div><img src="BBC.jpg" width="200px" align="right"></div>

```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data loading
```{r clean data}
startup_data <- read_csv("data/startup data.csv") 
```

```{r}
glimpse(startup_data)

head(startup_data)

describe(startup_data) 

# add to new data frame to process and clean the data
startup_data_process <- startup_data
```

# Data cleaning

After skimming the data to get a good overview, we will clean the data. First, we will check for missing values and duplicates.


```{r clean names}
# clean names
startup_data_process <- clean_names(startup_data_process)  
```


## Duplicates
```{r,echo=FALSE}
# remove empty columns and rows
startup_data_process <- remove_empty(startup_data_process, which = c("rows","cols"))

# check for duplicates
dupes <- startup_data_process %>% 
  get_dupes(object_id)

dupes
```

There is one duplicate for the start-up "Redwood Systems", which have slightly different coordinates. Perhaps, they have moved locations but since they are both in California and still have the same zip code we will just remove the row that does not have an exact address. 

```{r remove duplicate}
# removing the duplicate row
startup_data_process <- startup_data_process[ !(startup_data_process$unnamed_0 == 505), ]

# checking if there still are duplicates
dupes <- startup_data_process %>% 
  get_dupes(object_id)

dupes

```

## Missing data
After there are now more duplicates, we will start dealing with missing data.

```{r}
# investigate the missing values
describe(startup_data_process)    

#  use the md.pattern function from MICE package
md.pattern(startup_data_process, rotate.names = T)
```

There are some missing values for 
- Unnamed_6: this is a more detailed address, we will delete this column
- closed_at 
- age_first_milestone_year 
- age_last_milestone_year
- state_code.1

```{r missing values}
# delete unnamed_6
startup_data_process <- startup_data_process %>%
  select(-unnamed_6)

# cross-check if closed_at only occurs for start-ups that are not acquired
check_closedat <- startup_data_process %>%
  filter(is.na(closed_at) & status == "closed")
# this is the case, so we will leave na here

# cross-check if milestone values are missing if there have not been any milestones
check_milestones <- startup_data_process %>%
  filter((is.na(age_first_milestone_year) & milestones != 0) | # or
           (is.na(age_last_milestone_year) & milestones != 0))
# this is the case, so we will leave na here

# replace the missing state, which is CA (after research)
startup_data_process$state_code_1 <- ifelse(is.na(startup_data_process$state_code_1), 'CA', startup_data_process$state_code_1)
```


## Data types
Next, we will look at the data types. The dates still have to be put into the correct data type

Other ones as well?

```{r date data type}
# converting the dates into data format
startup_data_process <- startup_data_process %>%
  mutate(founded_at = mdy(founded_at), 
         closed_at = mdy(closed_at), 
         first_funding_at = mdy(first_funding_at), 
         last_funding_at = mdy(last_funding_at))
```



## Create new variables 
create age in year
create year founded (extract from day)
create area variable (West coast, East Cost etc)
create
```{r}
# create age
startup_data_process2 <- startup_data_process %>%
  mutate(age_Dec2020 = floor(age_calc(startup_data_process$founded_at, units = "years")))
           age_calc(dob, enddate = Sys.Date(), units = "years", precise = TRUE))
  
  
# create year founded  
startup_data_process <- startup_data_process %>% 
  mutate(year_founded = year(founded_at))
```

```{r}
# make a new category variables -> maybe use top 6 and rest into others 
startup_data_process <- startup_data_process %>% 
  mutate(category1 = ifelse ((category_code != 'software' & 
                                category_code!= 'web' & 
                                category_code != 'mobile' & 
                                category_code != 'enterprise' & 
                                category_code != 'advertising' & 
                                category_code != 'games_video' & 
                                category_code != 'ecommerce' & 
                                category_code != 'biotech' & 
                                category_code != 'consulting'), 
                             'other_category', 
                             startup_data_process$category_code))
```


After the data cleaning we will assign it back to the original data set and then start our exploratory data analysis.
```{r}
# assign the cleaned data back to the original data set so that we can work
startup_data <- startup_data_process
```


# Exploratory data analaysis

## Check numerical variables
iv) Check max, min, and distribution of numerical values.
- some ages are negative -> what do we do with these? (either make 0 or delete) -> most differences are very small
make those with less than a month 0, others delete

### Funding Amount
First, we look into the distribution of the funding amount. It is highly right-skewed, which is why we take the log
```{r}
startup_data %>% 
  ggplot(aes(
    x = funding_total_usd
  )) +
    geom_boxplot()+
  coord_flip()

startup_data %>% 
  ggplot(aes(
    x = funding_total_usd
  )) +
    geom_histogram() 

startup_data %>% 
  ggplot(aes(
    x = log(funding_total_usd)
  )) +
    geom_boxplot() +
    coord_flip()

startup_data %>% 
  ggplot(aes(
    x = log(funding_total_usd)
  )) +
    geom_histogram()

```


```{r}
startup_data %>% 
  arrange(desc(funding_total_usd)) %>% 
  head(10)

startup_data_process %>% 
  arrange(funding_total_usd) %>% 
  head(10)
```
### Funding rounds
```{r}
# startups according to funding round
startup_data %>% 
  group_by(funding_rounds) %>% 
  summarise(count_funding=n())
```



### Age (funding & milestones)

```{r}
startup_data %>% 
  ggplot(aes(
    x = age_first_funding_year,
    colour = status
  )) +
  geom_density()

startup_data %>% 
  ggplot(aes(
    x = age_last_funding_year,
    colour = status
  )) +
  geom_density()

startup_data %>% 
  ggplot(aes(
    x = age_first_milestone_year,
    colour = status
  )) +
  geom_density()

startup_data %>% 
  ggplot(aes(
    x = age_last_milestone_year,
    colour = status
  )) +
  geom_density()
```

```{r}
startup_data %>% 
  ggplot(aes(
    x = milestones,
    fill = status
  )) +
  geom_bar()

startup_data %>% 
  ggplot(aes(
    x = funding_rounds,
    fill = status
  )) +
  geom_bar()

```


## Check categorical variables
-> Names and distributions of categorical values.
For the categorical variables, we looked into the sectors:

# Categories
```{r EDA sectors}
startup_data %>%
  group_by(category_code) %>% 
  summarise(count_category = n()) %>%
  arrange(desc(count_category))

# we have 35 categories of startups  with the highest number of startups in software

startup_data %>%
  group_by(category_code) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(
    x = reorder(category_code, count),
    y = count
  )) +
  geom_col() +
  coord_flip() +
  labs(
    x = "startup category",
    y = "number of startups"
  )

startup_data %>% 
  group_by(category_code, status) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(
    x = reorder(category_code, count),
    y = count,
    fill = reorder(status, desc(status))
  )) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = c("#FF3333", "#00CC66")) +
  labs(fill = "start up status",
       x = "category")

```

### States and Location
Next, we will look at the locations of the start-ups.
Start-ups are located in 35 different states, with most of them being in California
```{r}
# look at the start-ups per state
startup_data %>% 
  group_by(state_code_1) %>%
  summarise(count_state = n()) %>%
  arrange(desc(count_state))

# we have 35 states with startups with highest number of startups in California
```


```{r }

library(sf)
remotes::install_github("UrbanInstitute/urbnmapr")
library(urbnmapr)

counties_sf <- get_urbn_map("counties", sf = TRUE)

counties_sf

class(counties_sf)
counties_sf$geometry

counties_sf <- counties_sf %>% 
st_transform(4326)

counties_sf %>% 
  ggplot(aes()) +
  geom_sf(fill = "grey70", colour = "#ffffff") +
  geom_point(data = startup_data, aes(
    x = longitude,
    y = latitude
  ))

startup_data %>% 
  filter(longitude > -20)

num_by_state <- startup_data %>% 
  group_by(state_code) %>% 
  summarise(count = n())

counties_sf_heat <- counties_sf %>% 
  left_join(num_by_state, by = c("state_abbv" = "state_code"))

counties_sf_heat %>% 
  ggplot(aes()) +
  geom_sf(aes(fill = count)) +
  scale_fill_gradient(low = "blue", high = "#98ff98")

```

# Visualisations

## Category -> Melonica, Jun
Which categories are most successful / get most funding? or similar


Josi: I already played with this, maybe you can use it:
Which industry receives the most total funding?

```{r}
funding_total <- startup_data %>%
  group_by(category1) %>%
  summarise(total_funding = (sum(funding_total_usd))/1000000) 

funding_total_plot <- funding_total %>% 
  ggplot(aes(x = total_funding, y = reorder(category1, total_funding), fill = category1)) +
  geom_bar(stat="identity")

funding_total_plot
# funding in millions
```



Which industry receives the most funding on average?
```{r}
funding_average <- startup_data %>%
  group_by(category1) %>%
  summarise(average_funding = (mean(funding_total_usd))/1000000) 

funding_average_plot <- funding_average %>% 
  ggplot(aes(x = average_funding, y = reorder(category1, average_funding), fill = category1)) +
  geom_bar(stat="identity")

funding_average_plot
# funding in millions
```

## Location -> Rick, Mehdi
make startups map, identifying the next Silicon Valley.
maybe look at funding per state / success rate per state
startups per population

## Time: When do we have to reach our first milestone -> Peijun, Josi













# Prediction 
model: Predict a startup's future based on its current characteristics
data modelling to select the features that might influence startups funding and outcomes.
### Logistic regression to predict status
```{r}
startup_data <- startup_data %>%
  mutate(status = if_else(status == "acquired", 1, 0))
```

```{r}
# we select only the relevant variables
startup_data_select <- startup_data %>%
  select(-zip_code, -city, -latitude, -longitude, -name, -id, -founded_at, -closed_at, -first_funding_at, -last_funding_at)

set.seed(1212)

train_test_split <- initial_split(startup_data_select, prop = 0.8) #training set contains 80% of the data

# Create the training and testing datasets
training <- training(train_test_split)
testing <- testing(train_test_split)
```

just playing around with the model (will tune further if necessary)
```{r}
status_logreg <- glm(status ~ avg_participants + 
                           age_first_funding_year + 
                           age_last_funding_year + 
                           relationships + 
                           funding_rounds +
                           log(funding_total_usd) +
                           category1 +
                           milestones, data = training, family = "binomial")
summary(status_logreg)
```

```{r}
#in-sample confusion matrix with cut-off 0.25
p_in <- predict(status_logreg, training, type = "response") #predict probability of default on the training set

one_or_zero_in <- ifelse(p_in >0.25, "1", "0") 
p_class_in <- factor(one_or_zero_in, levels = levels(startup_data_select$status)) 
con_in <- confusionMatrix(p_class_in, training$status, positive="1") 
con_in
```


# try with LASSO maybe?





